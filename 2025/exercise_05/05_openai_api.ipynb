{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MeFYJ2_x51c"
      },
      "source": [
        "# 第五回AI<画像/GPT>技術者育成講座\n",
        "目次\n",
        "- OpenAI APIのインストール\n",
        "- 環境変数の設定\n",
        "- 関数の定義\n",
        "- 課題例①\n",
        "- 課題例②\n",
        "\n",
        "注意点\n",
        "- この演習はGoogle Colaboratyで実行することを想定しています"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxhRl-7xyWKe"
      },
      "source": [
        "## OpenAI APIのインストール (+必要なライブラリをインストール)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "- [公式ドキュメント](https://platform.openai.com/docs/api-reference?lang=python)\n",
        "- [GitHub](https://github.com/openai/openai-python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiwAsGdgxQ5P"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインストール\n",
        "!pip install openai==1.109.1\n",
        "# グラフを日本語フォントに対応させるライブラリ\n",
        "!pip install japanize-matplotlib\n",
        "# データセットをダウンロードするライブラリ\n",
        "!pip install datasets==3.6.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAsk3NUn0qNb"
      },
      "source": [
        "## 環境変数の設定\n",
        "左のタブの`シークレット`から`OPENAI_API_KEY`を設定\n",
        "\n",
        "\n",
        "<img width=500 src=\"https://github.com/HarmoLab/aitr/blob/main/2023/exercise_04/colab_secret.png?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWDev_1pktR5"
      },
      "source": [
        "## 使用する関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnEdyw5p9PFS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= userdata.get('OPENAI_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAM-P6N7SO39"
      },
      "outputs": [],
      "source": [
        "# promptから料金を出力する関数\n",
        "def calculate_credit(model:str, input_tokens:int, output_tokens:int) -> float:\n",
        "    yen_rate = 150 # $1 = 150円で計算\n",
        "    if model == \"gpt-5-mini-2025-08-07\":\n",
        "        input_credit = (0.0025 * yen_rate) / 1000\n",
        "        output_credit = (0.002 * yen_rate) / 1000\n",
        "    elif model == \"gpt-5-2025-08-07\":\n",
        "        input_credit = (0.0125 * yen_rate) / 1000\n",
        "        output_credit = (0.01 * yen_rate) / 1000\n",
        "    elif model == \"gpt-5.1-2025-11-13\":\n",
        "        input_credit = (0.0125 * yen_rate) / 1000\n",
        "        output_credit = (0.01 * yen_rate) / 1000\n",
        "    else:\n",
        "        assert False, f\"モデル名: {model}の料金計算はできません。modelは'gpt-5-2025-08-07', または'gpt-5-mini-2025-08-07', または 'gpt-5.1-2025-11-13'を使用してください。\"\n",
        "    total_credit = round(input_credit * input_tokens + output_credit * output_tokens, 2)\n",
        "    print(f\"使用したモデル: {model}, 料金: {total_credit}円\")\n",
        "    return total_credit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH3JKX5IyiFM"
      },
      "outputs": [],
      "source": [
        "# forでループするために関数化 (RateLimit対策のためtenacityのデコーダを採用)\n",
        "# 参考: https://cookbook.openai.com/examples/how_to_handle_rate_limits\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "def simple_completion(model_name:str, system_prompt:str, user_prompt:str, response_format):\n",
        "    response = client.beta.chat.completions.parse(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_prompt\n",
        "            },\n",
        "        ],\n",
        "        model=model_name,\n",
        "        response_format=response_format,\n",
        "        timeout=15\n",
        "    )\n",
        "    # 料金の計算\n",
        "    credit = calculate_credit(model_name, response.usage.prompt_tokens, response.usage.completion_tokens)\n",
        "    parsed_data = response.choices[0].message.parsed\n",
        "    return response, parsed_data, credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hosmu9p5u4Iz"
      },
      "source": [
        "### chat.completions.createに使用する引数について\n",
        "公式ドキュメント: https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "### 主要な引数\n",
        "- model (必須)\n",
        "    - 使用する学習モデル (本演習では\"gpt-4o-mini-2024-07-18\"または\"gpt-4o-2024-08-06\"を使用)\n",
        "- messages (必須)\n",
        "    - role\n",
        "        - system: アシスタントの動作を設定\n",
        "        - assistant: アシスタントの望ましい動作を設定 (ユーザも作成可)\n",
        "        - user: ユーザの指示\n",
        "    - content\n",
        "        - roleに対して入力する文章\n",
        "- max_tokens: int or null\n",
        "    - 生成するトークンの最大数。出力の長さを制限することが可能\n",
        "- n: int or null\n",
        "    - 生成するレスポンスの数 (デフォルト: 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ceALdQ60jb"
      },
      "source": [
        "## 演習課題例①: **Amazonのレビュー分類**\n",
        "- 今回使用するデータセット (前回演習と同じデータ)\n",
        "    - Amazon Reviews Multi:\n",
        "https://huggingface.co/datasets/mteb/amazon_reviews_multi/viewer/ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHaeV6_c7JZf"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "# Amazonレビューのデータセット(日本語)をダウンロード\n",
        "# 今回はダウンロード時間を減らすために検証データ (validation)のみ取得\n",
        "dataset = datasets.load_dataset(\"mteb/amazon_reviews_multi\", \"ja\", split=\"validation\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QuYJkJiixyI"
      },
      "source": [
        "### データの用意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC-cpkRO9PJb"
      },
      "outputs": [],
      "source": [
        "k = 10 # 10件のレビュー文に対する評価\n",
        "shuffled_dataset = dataset.shuffle(seed=70) # データセットをシャッフル\n",
        "\n",
        "# 検証データ\n",
        "review_list = shuffled_dataset[:k][\"text\"]\n",
        "label_list = shuffled_dataset[:k][\"label\"]\n",
        "\n",
        "# few-shotデータ\n",
        "num_few_shot = 4  # few-shotの数\n",
        "review_list_few_shot = shuffled_dataset[k: k + num_few_shot][\"text\"]\n",
        "label_list_few_shot = shuffled_dataset[k: k + num_few_shot][\"label\"]\n",
        "\n",
        "# テストデータ\n",
        "test_review_list = shuffled_dataset[-k:][\"text\"]\n",
        "test_label_list = shuffled_dataset[-k:][\"label\"]\n",
        "\n",
        "\n",
        "print(review_list)\n",
        "print(label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 構造化出力のためのクラスを定義"
      ],
      "metadata": {
        "id": "Ephbr0JhSv4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "# 構造化出力のためのクラスの定義\n",
        "class AmazonReview(BaseModel):\n",
        "    \"\"\"\n",
        "    アマゾンのレビューに対する評価\n",
        "    \"\"\"\n",
        "    review: int = Field(\n",
        "        -1,\n",
        "        description=\"レビュー文を0から4までの整数に分類してください。\"\n",
        "    )"
      ],
      "metadata": {
        "id": "XulqisIbS1Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqYsZPa6Iw0s"
      },
      "source": [
        "### 検証データによる評価\n",
        "\n",
        "* 最も性能が良いプロンプトを見つける"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t136qNcGi0z7"
      },
      "source": [
        "#### zero-shotプロンプトを使用したレビューの分類\n",
        "\n",
        "* 検証データを用いたレビュー分類\n",
        "* 回答例を与えないzero-shotプロンプトを使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MxWS8_EESiI"
      },
      "outputs": [],
      "source": [
        "# 以下のsystem prompt (zero-shotプロンプト) を用いたレビュー分類\n",
        "system_prompt = \"\"\"\n",
        "レビュー文を0から4までの整数に分類してください。\n",
        "\"\"\"\n",
        "\n",
        "# 使用するモデルの設定\n",
        "model = \"gpt-5-mini-2025-08-07\"\n",
        "\n",
        "predict_label_list = [] # -1(出力形式のエラー), 0, 1, 2, 3, 4\n",
        "total_credit = 0\n",
        "for i, (review, label) in enumerate(zip(review_list, label_list)):\n",
        "    print(f\"\\n^^^^^^^^^^ {i+1}件目のレビュー ^^^^^^^^^^\")\n",
        "    print(\"--- レビュー文 ---\")\n",
        "    print(review)\n",
        "    print(\"--- 実際の評価 ---\")\n",
        "    print(label)\n",
        "    response, parsed_data, credit = simple_completion(\n",
        "        model,\n",
        "        system_prompt,\n",
        "        review,\n",
        "        AmazonReview\n",
        "    )\n",
        "    total_credit += credit\n",
        "    print(\"--- ChatGPTの回答 ---\")\n",
        "    print(response)\n",
        "    print(parsed_data.review)\n",
        "    predict_label_list.append(parsed_data.review)\n",
        "\n",
        "print(f\"合計金額: {total_credit}円\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o20sszUDVDOq"
      },
      "outputs": [],
      "source": [
        "print(\"--- 実際の評価 ---\")\n",
        "print(label_list)\n",
        "print(\"--- 予測した評価--- \")\n",
        "print(predict_label_list)\n",
        "\n",
        "# 評価\n",
        "## 実際の評価と予測した評価の差の合計を評価値 (loss)\n",
        "## 予測した評価が-1（出力形式のエラー）の場合は+6\n",
        "\n",
        "validation_score = 0 # 評価値\n",
        "correct_answer = 0 # 正解数\n",
        "for actual, predict in zip(label_list, predict_label_list):\n",
        "    if not actual == predict:\n",
        "        if predict == -1:\n",
        "            validation_score += 6\n",
        "            continue\n",
        "        validation_score += abs(actual - predict)\n",
        "    else:\n",
        "        correct_answer += 1\n",
        "print(\"\\n--- 正答率 ---\")\n",
        "print(f\"{correct_answer/len(label_list)*100} %\")\n",
        "print(\"--- 評価値 (低いほうが良い結果) ---\")\n",
        "print(validation_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2RTFtA_NaKg"
      },
      "outputs": [],
      "source": [
        "# 混同行列で結果を可視化\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "import seaborn as sns\n",
        "\n",
        "# 混同行列に使用するラベル作成\n",
        "label_name = list(range(-1, 5))  # [-1, 0, .., 4]\n",
        "\n",
        "# 混同行列の作成\n",
        "confusion_mtr = confusion_matrix(label_list,  predict_label_list, labels=label_name)\n",
        "\n",
        "# ラベル名\n",
        "label_name = list(range(-1, 5))\n",
        "\n",
        "# 混同行列を可視化\n",
        "sns.heatmap(\n",
        "    confusion_mtr,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=label_name,\n",
        "    yticklabels=label_name\n",
        ")\n",
        "plt.xlabel('予測した評価')\n",
        "plt.ylabel('実際の評価')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ozOeWB-Acb"
      },
      "source": [
        "#### few-shotプロンプトを使ったレビューの分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fSDDypE-DwG"
      },
      "outputs": [],
      "source": [
        "num_few_shot = 4  # few-shotで使用する回答例の数\n",
        "\n",
        "# few-shotプロンプトに使用するデータ\n",
        "review_list_few_shot = shuffled_dataset[k: k + num_few_shot][\"text\"]\n",
        "label_list_few_shot = shuffled_dataset[k: k + num_few_shot][\"label\"]\n",
        "\n",
        "print(review_list_few_shot)\n",
        "print(label_list_few_shot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxangjmO-Dty"
      },
      "outputs": [],
      "source": [
        "# few-shotプロンプトの作成\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "レビュー文を0から4までの整数に分類してください。\n",
        "\"\"\"\n",
        "\n",
        "few_shot_prompt = \"### 例\\n\"\n",
        "for i in range(num_few_shot):\n",
        "    few_shot_prompt += \"レビュー文: \" + review_list_few_shot[i]\n",
        "    few_shot_prompt += \"\\n\" + str(label_list_few_shot[i]) + \"\\n\\n\"\n",
        "system_prompt += \"\\n\" + few_shot_prompt\n",
        "\n",
        "print(system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU1GBD_w_zxK"
      },
      "outputs": [],
      "source": [
        "## few-shotプロンプトを用いたレビュー分類\n",
        "\n",
        "# 使用するモデルの設定\n",
        "model = \"gpt-5-mini-2025-08-07\"\n",
        "\n",
        "predict_label_list = []  # -1(出力形式のエラー), 0, 1, 2, 3, 4\n",
        "total_credit = 0\n",
        "for i, (review, label) in enumerate(zip(review_list, label_list)):\n",
        "    # user_prompt = \"レビュー文: \" + review + \"\\n評価: \"\n",
        "    user_prompt = \"レビュー文: \" + review + \"\\n\"\n",
        "    print(f\"\\n^^^^^^^^^^ {i+1}件目のレビュー ^^^^^^^^^^\")\n",
        "    print(\"--- レビュー文 ---\")\n",
        "    print(user_prompt)\n",
        "    print(\"--- 実際の評価 ---\")\n",
        "    print(label)\n",
        "    response, parsed_data, credit = simple_completion(model, system_prompt, review, AmazonReview)\n",
        "    total_credit += credit\n",
        "    print(\"--- ChatGPTの回答 ---\")\n",
        "    print(response)\n",
        "    print(parsed_data.review)\n",
        "    predict_label_list.append(parsed_data.review)\n",
        "\n",
        "print(f\"合計金額: {total_credit}円\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKopv4u0-DrS"
      },
      "outputs": [],
      "source": [
        "print(\"--- 実際の評価 ---\")\n",
        "print(label_list)\n",
        "print(\"--- 予測した評価--- \")\n",
        "print(predict_label_list)\n",
        "\n",
        "# 評価\n",
        "## 実際の評価と予測した評価の差の合計を評価値 (loss)\n",
        "## 予測した評価が-1（出力形式のエラー）の場合は+6\n",
        "\n",
        "validation_score = 0 # 評価値\n",
        "correct_answer = 0 # 正解数\n",
        "for actual, predict in zip(label_list, predict_label_list):\n",
        "    if not actual == predict:\n",
        "        if predict == -1:\n",
        "            validation_score += 6\n",
        "            continue\n",
        "        validation_score += abs(actual - predict)\n",
        "    else:\n",
        "        correct_answer += 1\n",
        "print(\"\\n--- 正答率 ---\")\n",
        "print(f\"{correct_answer/len(label_list)*100} %\")\n",
        "print(\"--- 評価値 (低いほうが良い結果) ---\")\n",
        "print(validation_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0pjhPaYRHTa"
      },
      "outputs": [],
      "source": [
        "# 混同行列で結果を可視化\n",
        "\n",
        "label_name = list(range(-1, 5))  # [-1, 0, .., 4]\n",
        "\n",
        "# 混同行列の作成\n",
        "confusion_mtr = confusion_matrix(label_list, predict_label_list, labels=label_name)\n",
        "\n",
        "# ラベル名\n",
        "label_name = list(range(-1, 5))\n",
        "\n",
        "# 混同行列を可視化\n",
        "sns.heatmap(confusion_mtr, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=label_name, yticklabels=label_name)\n",
        "plt.xlabel('予測した評価')\n",
        "plt.ylabel('実際の評価')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsHzR4hJXw7I"
      },
      "source": [
        "### テストデータを用いた評価\n",
        "\n",
        "* few-shotプロンプトを用いてテストデータをレビュー分類\n",
        "  * 検証データについてfew-shotプロンプトを用いた結果が良かったため"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck0cLkBaXyt5"
      },
      "outputs": [],
      "source": [
        "test_review_list = shuffled_dataset[-k:][\"text\"]\n",
        "test_label_list = shuffled_dataset[-k:][\"label\"]\n",
        "print(test_review_list)\n",
        "print(test_label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddw05Q1QXyq0"
      },
      "outputs": [],
      "source": [
        "# テストデータで評価\n",
        "## 最も良かったfew-shotプロンプトを使用\n",
        "\n",
        "predict_label_list = [] # -1(出力形式のエラー), 0, 1, 2, 3, 4\n",
        "total_credit = 0\n",
        "for i, (review, label) in enumerate(zip(test_review_list, test_label_list)):\n",
        "    # user_prompt = \"レビュー文: \" + review + \"\\n評価: \"\n",
        "    user_prompt = \"レビュー文: \" + review + \"\\n\"\n",
        "    print(f\"\\n^^^^^^^^^^ {i+1}件目のレビュー ^^^^^^^^^^\")\n",
        "    print(\"--- レビュー文 ---\")\n",
        "    print(user_prompt)\n",
        "    print(\"--- 実際の評価 ---\")\n",
        "    print(label)\n",
        "    response, parsed_data, credit = simple_completion(model, system_prompt, review, AmazonReview)\n",
        "    total_credit += credit\n",
        "    print(\"--- ChatGPTの回答 ---\")\n",
        "    print(response)\n",
        "    print(parsed_data.review)\n",
        "    predict_label_list.append(parsed_data.review)\n",
        "\n",
        "print(f\"合計金額: {total_credit}円\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1REhPLPXym7"
      },
      "outputs": [],
      "source": [
        "print(\"--- 実際の評価 ---\")\n",
        "print(test_label_list)\n",
        "print(\"--- 予測した評価--- \")\n",
        "print(predict_label_list)\n",
        "\n",
        "# 評価\n",
        "## 実際の評価と予測した評価の差の合計を評価値 (loss)\n",
        "## 予測した評価が-1（出力形式のエラー）の場合は+6\n",
        "\n",
        "validation_score = 0 # 評価値\n",
        "correct_answer = 0 # 正解数\n",
        "for actual, predict in zip(test_label_list, predict_label_list):\n",
        "    if not actual == predict:\n",
        "        if predict == -1:\n",
        "            validation_score += 6\n",
        "            continue\n",
        "        validation_score += abs(actual - predict)\n",
        "    else:\n",
        "        correct_answer += 1\n",
        "print(\"\\n--- 正答率 ---\")\n",
        "print(f\"{correct_answer/len(test_label_list)*100} %\")\n",
        "print(\"--- 評価値 (低いほうが良い結果) ---\")\n",
        "print(validation_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMZNY59PcZZm"
      },
      "outputs": [],
      "source": [
        "# 混同行列で結果を可視化\n",
        "\n",
        "label_name = list(range(-1, 5))  # [-1, 0, .., 4]\n",
        "\n",
        "# 混同行列の作成\n",
        "confusion_mtr = confusion_matrix(test_label_list, predict_label_list, labels=label_name)\n",
        "\n",
        "# ラベル名\n",
        "label_name = list(range(-1, 5))\n",
        "\n",
        "# 混同行列を可視化\n",
        "sns.heatmap(confusion_mtr, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=label_name, yticklabels=label_name)\n",
        "plt.xlabel('予測した評価')\n",
        "plt.ylabel('実際の評価')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YU8u_iSO7Ny"
      },
      "source": [
        "## 演習課題例②: **ニュース記事からカテゴリ分類**\n",
        "\n",
        "* Yahooニュースからニュース記事の概要、カテゴリを収集\n",
        "  * スポーツ、経済の2カテゴリからランダムに\n",
        "  * スポーツと経済のどちらにも該当するケースは選ばないように収集\n",
        "  * 合わせて24記事収集 (スポーツ12記事、経済12記事)\n",
        "  * Googleスプレッドシートを使用し、カテゴリ、文章の2つを手作業で記入\n",
        "\n",
        "* ChatGPTによるカテゴリ分類\n",
        "  * zero-shotプロンプトを使用した例\n",
        "  * few-shotプロンプトを使用した例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkNaVOQQjtDa"
      },
      "source": [
        "### 記事の収集とデータの読み込み\n",
        "\n",
        "* 各自で設定した課題に関するデータを収集してください\n",
        "\n",
        "* 今回の例では、以下のリンクのスプレッドシートを作成したと想定する\n",
        "  * https://docs.google.com/spreadsheets/d/1eJV-uRF1Mbpt_MokNfMvFewarMBsqWfM32W5_HdGvow/edit?usp=sharing\n",
        "\n",
        "  * 以下より、スプレッドシートをダウンロード\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1SdXP1PMFsQtkAgqyhlL-W9npfxYHJWGY\" width=50%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVu0_re-g0_"
      },
      "source": [
        "* ダウンロードしたデータをColab上にアップロード\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1YVJhXYVCEehBF_li5EiWjUxiwKepnaFY\" width=50%>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u27eeyvL9VNr"
      },
      "outputs": [],
      "source": [
        "SEED = 1000\n",
        "\n",
        "# スプレッドシートの読み込み\n",
        "df = pd.read_excel(\"yahoo_news_dataset.xlsx\")  #TODO: ここを各々のデータに置き換える\n",
        "\n",
        "df = df.sample(frac=1, random_state=SEED)  # データをシャッフル\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmCPSN30qIg1"
      },
      "outputs": [],
      "source": [
        "k = 10 # 10件のレビュー文に対する評価\n",
        "\n",
        "# 検証データ\n",
        "review_list = df[:k][\"文章\"].values.tolist()     # 入力文章が格納されている列名\n",
        "label_list = df[:k][\"カテゴリ\"].values.tolist()  # カテゴリ、ラベルが格納されている列名\n",
        "\n",
        "# few-shotデータ\n",
        "num_few_shot = 4  # few-shotの数\n",
        "review_list_few_shot = df[k: k + num_few_shot][\"文章\"].values.tolist()\n",
        "label_list_few_shot = df[k: k + num_few_shot][\"カテゴリ\"].values.tolist()\n",
        "\n",
        "# テストデータ\n",
        "test_review_list = df[-k:][\"文章\"].values.tolist()\n",
        "test_label_list = df[-k:][\"カテゴリ\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 構造化出力のためのクラスを定義"
      ],
      "metadata": {
        "id": "R8bZIc-mVKZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "# 構造化出力のためのクラスの定義\n",
        "class NewsCategory(BaseModel):\n",
        "    \"\"\"\n",
        "    ヤフーニュースのカテゴリ\n",
        "    \"\"\"\n",
        "    category: Literal[\"スポーツ\", \"経済\"] = Field(\n",
        "        ...,\n",
        "        description=\"文章を'経済'もしくは'スポーツ'のどちらかで回答する。\"\n",
        "    )"
      ],
      "metadata": {
        "id": "PEezU3lfVMCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QiqpCkpFlS_"
      },
      "source": [
        "### 検証データによる評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvgalpkJ_rAr"
      },
      "source": [
        "#### zero-shotプロンプトによるカテゴリ分類\n",
        "\n",
        "* 検証データを用いたレビュー分類\n",
        "* 回答例を与えないzero-shotプロンプトを使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13yaqCdEqId2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# zero-shotプロンプト\n",
        "system_prompt = \"\"\"\n",
        "文章を経済または、スポーツに分類してください。\n",
        "'経済'もしくは'スポーツ'のどちらかで回答してください。\n",
        "\"\"\"\n",
        "\n",
        "# 使用するモデルの設定\n",
        "model = \"gpt-5-mini-2025-08-07\"\n",
        "\n",
        "predict_label_list = []  # '経済', 'スポーツ'\n",
        "total_credit = 0\n",
        "for i, (text, label) in enumerate(zip(review_list, label_list)):\n",
        "    # print(text)\n",
        "    # print(label)\n",
        "    # break\n",
        "    print(f\"\\n^^^^^^^^^^ 記事{i+1} ^^^^^^^^^^\")\n",
        "    print(\"--- 文章 ---\")\n",
        "    print(text)\n",
        "    print(\"--- 実際のカテゴリ ---\")\n",
        "    print(label)\n",
        "    response, parsed_data, credit = simple_completion(model, system_prompt, text, NewsCategory)\n",
        "    total_credit += credit\n",
        "    print(\"--- ChatGPTの回答 ---\")\n",
        "    print(response)\n",
        "    print(parsed_data.category)\n",
        "\n",
        "    predict_label_list.append(parsed_data.category)\n",
        "print(f\"合計金額: {total_credit}円\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UM8bdBHDUEG"
      },
      "outputs": [],
      "source": [
        "print(\"--- 実際の評価 ---\")\n",
        "print(label_list)\n",
        "print(\"--- 予測した評価--- \")\n",
        "print(predict_label_list)\n",
        "\n",
        "# 評価\n",
        "## 実際の評価と予測した評価の差の合計を評価値 (loss)\n",
        "\n",
        "correct_answer = 0 # 正解数\n",
        "for actual, predict in zip(label_list, predict_label_list):\n",
        "    if actual == predict:\n",
        "        correct_answer += 1\n",
        "print(\"\\n--- 正答率 ---\")\n",
        "print(f\"{correct_answer/len(label_list)*100} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ6DRDVrDT5x"
      },
      "outputs": [],
      "source": [
        "# 混同行列で結果を可視化\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "\n",
        "# 混同行列に使用するユニークなラベル作成\n",
        "label_name = list(set(label_list + predict_label_list))  # ['経済', 'スポーツ']\n",
        "\n",
        "# 混同行列の作成\n",
        "confusion_mtr = confusion_matrix(label_list, predict_label_list, labels=label_name)\n",
        "\n",
        "# 混同行列を可視化\n",
        "sns.heatmap(confusion_mtr, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_name, yticklabels=label_name)\n",
        "plt.xlabel('予想した評価')\n",
        "plt.ylabel('実際の評価')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IolPZhtvGV1o"
      },
      "source": [
        "zero-shotプロンプトで良い精度だったので、このプロンプトでテストデータを評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ1qWvBVFfeM"
      },
      "source": [
        "### テストデータを分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Renbf7IOG97G"
      },
      "outputs": [],
      "source": [
        "# zero-shotプロンプト\n",
        "system_prompt = \"\"\"\n",
        "文章を経済または、スポーツに分類してください。\n",
        "'経済'もしくは'スポーツ'のどちらかで回答してください。\n",
        "\"\"\"\n",
        "\n",
        "predict_label_list = []  # '経済', 'スポーツ'\n",
        "total_credit = 0\n",
        "for i, (text, label) in enumerate(zip(test_review_list, test_label_list)):\n",
        "    # print(text)\n",
        "    # print(label)\n",
        "    # break\n",
        "    print(f\"\\n^^^^^^^^^^ 記事{i+1} ^^^^^^^^^^\")\n",
        "    print(\"--- 文章 ---\")\n",
        "    print(text)\n",
        "    print(\"--- 実際のカテゴリ ---\")\n",
        "    print(label)\n",
        "    response, parsed_data, credit = simple_completion(model, system_prompt, text, NewsCategory)\n",
        "    total_credit += credit\n",
        "    print(\"--- ChatGPTの回答 ---\")\n",
        "    print(response)\n",
        "    print(parsed_data.category)\n",
        "\n",
        "    predict_label_list.append(parsed_data.category)\n",
        "print(f\"合計金額: {total_credit}円\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwG238STG0hd"
      },
      "outputs": [],
      "source": [
        "print(\"--- 実際の評価 ---\")\n",
        "print(test_label_list)\n",
        "print(\"--- 予測した評価--- \")\n",
        "print(predict_label_list)\n",
        "\n",
        "# 評価\n",
        "## 実際の評価と予測した評価の差の合計を評価値 (loss)\n",
        "\n",
        "correct_answer = 0 # 正解数\n",
        "for actual, predict in zip(test_label_list, predict_label_list):\n",
        "    if actual == predict:\n",
        "        correct_answer += 1\n",
        "print(\"\\n--- 正答率 ---\")\n",
        "print(f\"{correct_answer/len(test_label_list)*100} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZSV1DwiG0UJ"
      },
      "outputs": [],
      "source": [
        "# 混同行列に使用するユニークなラベル作成\n",
        "label_name = list(set(test_label_list + predict_label_list))  # ['経済', 'スポーツ']\n",
        "\n",
        "# 混同行列の作成\n",
        "confusion_mtr = confusion_matrix(test_label_list, predict_label_list, labels=label_name)\n",
        "\n",
        "# 混同行列を可視化\n",
        "sns.heatmap(confusion_mtr, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_name, yticklabels=label_name)\n",
        "plt.xlabel('予想した評価')\n",
        "plt.ylabel('実際の評価')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}