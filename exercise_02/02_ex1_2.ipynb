{"cells":[{"cell_type":"markdown","metadata":{"id":"yUIEb1L3DpAX"},"source":["# **演習Ⅰ 課題2**\n","\n","中間層を2層に変更してコードを実行してください。\n","\n","各層のノード数は128, 64に設定してください。\n","\n","※上部にある「ドライブにコピー」で自分のドライブにコピーしてから編集・実行してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbbwohRv8vkx"},"outputs":[],"source":["# ライブラリのインポート\n","import os\n","import time\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","# Google DriveをマウントしてDrive内のファイルにアクセスできるようにする\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qXw2m-I8vky"},"outputs":[],"source":["# 各種設定\n","BATCH_SIZE = 128 # ミニバッチのサイズ\n","MAX_EPOCH = 10   # エポック数（訓練データ全体を何回繰り返して学習させるか）\n","\n","# シード値の固定\n","# シードを固定すると毎回同じ結果が得られる（再現性の確保）\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msK5WhqG8vky"},"outputs":[],"source":["# データの前処理の方法を定義\n","transform = transforms.Compose([\n","\ttransforms.ToTensor() # データをテンソルに変換\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObR1S9-i8vky"},"outputs":[],"source":["# 訓練データ、検証データ、テストデータの準備\n","# 手書き数字画像データセットMNISTを使用\n","\n","# 訓練データの取得\n","train_dataset = datasets.MNIST(\n","\t\"./data\",            # データの保存先\n","\ttrain=True,          # 訓練データとして取得\n","\tdownload=True,       # データが存在しない場合はダウンロード\n","\ttransform=transform, # データに前処理を適用\n",")\n","\n","# 訓練データの一部を検証データとして分割\n","train_dataset, valid_dataset = torch.utils.data.random_split(\n","\t  train_dataset,\n","\t  [48000, 12000] # 48000枚を訓練データ、12000枚を検証データに分割\n",")\n","\n","# テストデータの取得\n","test_dataset = datasets.MNIST(\n","\t\"./data\",            # データの保存先\n","\ttrain=False,         # テストデータとして取得\n","\tdownload=True,       # データが存在しない場合はダウンロード\n","\ttransform=transform, # データに前処理を適用\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yJX4JWc8vkz"},"outputs":[],"source":["# データローダーの作成\n","# データセットからバッチを作成してモデルに供給する役割\n","\n","# 訓練データ用のデータローダー\n","train_loader = torch.utils.data.DataLoader(\n","\ttrain_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=True,          # 学習時はデータをシャッフル\n",")\n","# 検証データ用のデータローダー\n","valid_loader = torch.utils.data.DataLoader(\n","\tvalid_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=False,         # 検証時はシャッフルしない\n",")\n","# テストデータ用のデータローダー\n","test_loader = torch.utils.data.DataLoader(\n","\ttest_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=False,         # テスト時もシャッフルしない\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iI0RNeaS8vkz"},"outputs":[],"source":["# ニューラルネットワークの定義\n","class MLP(nn.Module):\n","\tdef __init__(self):\n","\t\t'''\n","\t\tニューラルネットワークの構造を定義\n","\t\t今回は「多層パーセプトロン（MLP）」というモデルを使用\n","\t\t'''\n","\t\tsuper(MLP, self).__init__()\n","\n","\t\t######## ↓ 課題2 編集部分① ########\n","\n","\t\t# 入力層から中間層への変換を定義\n","\t\t# 入力層のノード数：784個（28x28ピクセルの画像を一列のベクトルに変換）\n","\t\t# 中間層のノード数：16個\n","\t\tself.fc1 = nn.Linear(28 * 28, 16)\n","\n","\t\t# 中間層から出力層への変換を定義\n","\t\t# 出力層のノード数：10個（数字0〜9を予測）\n","\t\tself.fc_output = nn.Linear(16, 10)\n","\n","\t\t######## ↑ 課題2 編集部分① ########\n","\n","\tdef forward(self, x):\n","\t\t'''\n","\t\t入力から出力までの流れを定義\n","\t\t'''\n","\t\tx = x.view(-1, 28 * 28) # 28x28ピクセルの画像を一列のベクトルに変換\n","\n","\t\t######## ↓ 課題2 編集部分② ########\n","\n","\t\tx = self.fc1(x)         # 中間層の計算\n","\t\tx = F.relu(x)           # 活性化関数ReLUを適用\n","\t\tx = self.fc_output(x)   # 出力層の計算\n","\n","\t\t######## ↑ 課題2 編集部分② ########\n","\n","\t\treturn x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrMdSPQP8vkz"},"outputs":[],"source":["# 定義したニューラルネットワークのインスタンス化\n","model = MLP()\n","\n","# 損失関数の定義\n","loss_function = nn.CrossEntropyLoss()\n","\n","# 最適化手法と学習率の定義\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLKduK1T8vk0"},"outputs":[],"source":["# 学習を通しての損失を記録するためのリスト（学習曲線のプロット用）\n","train_losses = []\n","valid_losses = []\n","\n","# 学習にかかった時間の計測開始\n","start_time = time.time()\n","\n","print(\"\\n【学習開始】\\n\")\n","print(\"train_loss: 学習データにおける損失\")\n","print(\"valid_loss: 検証データにおける損失\\n\")\n","\n","# エポックごとの訓練損失と検証損失を出力\n","print(\"epoch\\ttrain_loss\\tvalid_loss\")\n","\n","for epoch in range(MAX_EPOCH):\n","\tmodel.train()        # モデルを訓練モードに設定\n","\ttrain_loss_list = [] # 訓練損失を保存するリスト\n","\n","\t# 訓練データでモデルを学習\n","\tfor x, label in train_loader:\n","\t\toptimizer.zero_grad()               # 勾配をリセット\n","\t\toutput = model(x)                   # モデルの出力を計算\n","\t\tloss = loss_function(output, label) # 損失を計算\n","\t\tloss.backward()                     # 勾配を計算\n","\t\toptimizer.step()                    # 勾配に基づいてパラメータを更新\n","\t\ttrain_loss_list.append(loss.item()) # バッチごとの損失を記録\n","\n","\ttrain_loss_mean = np.mean(train_loss_list) # エポックごとの平均訓練損失\n","\ttrain_losses.append(train_loss_mean)       # 訓練損失をリストに追加\n","\n","\tmodel.eval()         # モデルを評価モードに設定\n","\tvalid_loss_list = [] # 検証損失を保存するリスト\n","\n","\t# 検証データで損失を計算\n","\tfor x, label in valid_loader:\n","\t\toutput = model(x)                      # モデルの出力を計算\n","\t\tloss = loss_function(output, label)    # 損失を計算\n","\t\tvalid_loss_list.append(loss.item())    # バッチごとの損失を記録\n","\n","\tvalid_loss_mean = np.mean(valid_loss_list) # エポックごとの平均検証損失\n","\tvalid_losses.append(valid_loss_mean)       # 検証損失をリストに追加\n","\n","\tprint(\"{}\\t{:.8}\\t{:.8}\".format(epoch, train_loss_mean, valid_loss_mean))\n","\n","# 学習にかかった時間の計測終了\n","end_time = time.time()\n","print(\"\\n学習にかかった時間 : {} [sec]\".format(end_time - start_time))\n","\n","print(\"\\n【学習終了】\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"os24cyIT8vk0"},"outputs":[],"source":["# 学習曲線のプロット\n","plt.plot(range(MAX_EPOCH), train_losses, label='Training Loss')\n","plt.plot(range(MAX_EPOCH), valid_losses, label='Validation Loss', color=\"green\")\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Learning Curve')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjDa-rzt8vk1"},"outputs":[],"source":["# テストデータを使ってモデルを評価\n","model.eval() # モデルを評価モードに設定\n","test_loss = 0\n","test_correct = 0\n","test_total = 0\n","\n","# テストデータでの損失と正解率を計算\n","for x, label in test_loader:\n","\toutput = model(x)                            # モデルの出力を計算\n","\tloss = loss_function(output, label)          # 損失を計算\n","\t_, pred = torch.max(output.data, dim=1)      # 出力の最大値を持つクラスを予測\n","\ttest_correct += (pred == label).sum().item() # 正解の数をカウント\n","\ttest_total += label.size()[0]                # テストデータの総数をカウント\n","\n","# テストデータにおける正解率を計算して表示\n","test_accuracy = test_correct / test_total\n","print(\"テストデータにおける正解率 : {:.4f}\".format(test_accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"728S5dJb8vk1"},"outputs":[],"source":["# モデルの保存\n","model_dir = \"/content/drive/MyDrive/jts2024_2/model/\"\n","os.makedirs(model_dir, exist_ok=True)\n","save_path = model_dir + \"mlp_2.pt\"\n","torch.save(model.state_dict(), save_path)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
