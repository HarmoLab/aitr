{"cells":[{"cell_type":"markdown","metadata":{"id":"yUIEb1L3DpAX"},"source":["# **第2回 演習Ⅱ 課題1**\n","\n","コードを実行してください。\n","\n","※上部にある「ドライブにコピー」で自分のドライブにコピーしてから編集・実行してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbbwohRv8vkx"},"outputs":[],"source":["# ライブラリのインポート\n","import os\n","import time\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.simplefilter('ignore', UserWarning)\n","\n","# Google DriveをマウントしてDrive内のファイルにアクセスできるようにする\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qXw2m-I8vky"},"outputs":[],"source":["# 各種設定\n","BATCH_SIZE = 128 # ミニバッチのサイズ\n","MAX_EPOCH = 10   # エポック数（訓練データ全体を何回繰り返して学習させるか）\n","\n","# シード値の固定\n","# シードを固定すると毎回同じ結果が得られる（再現性の確保）\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msK5WhqG8vky"},"outputs":[],"source":["# データの前処理の方法を定義\n","transform = transforms.Compose([\n","\ttransforms.ToTensor() # データをテンソルに変換\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObR1S9-i8vky"},"outputs":[],"source":["# 訓練データ、検証データ、テストデータの準備\n","# 手書き数字画像データセットMNISTを使用\n","\n","# 訓練データの取得\n","train_dataset = datasets.MNIST(\n","\t\"./data\",            # データの保存先\n","\ttrain=True,          # 訓練データとして取得\n","\tdownload=True,       # データが存在しない場合はダウンロード\n","\ttransform=transform, # データに前処理を適用\n",")\n","\n","# 訓練データの一部を検証データとして分割\n","train_dataset, valid_dataset = torch.utils.data.random_split(\n","\t  train_dataset,\n","\t  [48000, 12000] # 48000枚を訓練データ、12000枚を検証データに分割\n",")\n","\n","# テストデータの取得\n","test_dataset = datasets.MNIST(\n","\t\"./data\",            # データの保存先\n","\ttrain=False,         # テストデータとして取得\n","\tdownload=True,       # データが存在しない場合はダウンロード\n","\ttransform=transform, # データに前処理を適用\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yJX4JWc8vkz"},"outputs":[],"source":["# データローダーの作成\n","# データセットからバッチを作成してモデルに供給する役割\n","\n","# 訓練データ用のデータローダー\n","train_loader = torch.utils.data.DataLoader(\n","\ttrain_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=True,          # 学習時はデータをシャッフル\n",")\n","# 検証データ用のデータローダー\n","valid_loader = torch.utils.data.DataLoader(\n","\tvalid_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=False,         # 検証時はシャッフルしない\n",")\n","# テストデータ用のデータローダー\n","test_loader = torch.utils.data.DataLoader(\n","\ttest_dataset,\n","\tbatch_size=BATCH_SIZE, # バッチサイズごとにデータを供給\n","\tshuffle=False,         # テスト時もシャッフルしない\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P0P_k3AAMIxZ"},"outputs":[],"source":["# 畳み込みニューラルネットワークの定義\n","class CNN(nn.Module):\n","  def __init__(self):\n","    '''\n","    畳み込みニューラルネットワークの構造を定義\n","    '''\n","    super(CNN, self).__init__()\n","\n","    # 畳み込み層1\n","    self.conv1 = nn.Conv2d(1, 8, 3)  # 28x28x1 -> 26x26x8\n","    # 畳み込み層2\n","    self.conv2 = nn.Conv2d(8, 16, 3) # 26x26x8 -> 24x24x16\n","    # 最大プーリング層\n","    self.pool = nn.MaxPool2d(2, 2)   # 24x24x16 -> 12x12x16\n","    # 全結合層\n","    self.fc1 = nn.Linear(12 * 12 * 16, 128) # 12x12x16 -> 128\n","    self.fc2 = nn.Linear(128, 64)           # 128 -> 64\n","    self.fc3 = nn.Linear(64, 10)            # 64 -> 10\n","\n","  def forward(self, x):\n","    '''\n","    入力から出力までの流れを定義\n","    '''\n","    x = F.relu(self.conv1(x))    # 畳み込み層1の計算 + 活性化関数ReLUの適用\n","    x = F.relu(self.conv2(x))    # 畳み込み層2の計算 + 活性化関数ReLUの適用\n","    x = self.pool(x)             # 最大プーリング\n","\n","    x = x.view(-1, 12 * 12 * 16) # 特徴マップを1次元のベクトルに変換\n","\n","    x = F.relu(self.fc1(x))      # 全結合層1の計算 + 活性化関数ReLUの適用\n","    x = F.relu(self.fc2(x))      # 全結合層2の計算 + 活性化関数ReLUの適用\n","    x = self.fc3(x)              # 出力層の計算\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrMdSPQP8vkz"},"outputs":[],"source":["# 定義した畳み込みニューラルネットワークのインスタンス化\n","model = CNN()\n","# 損失関数の定義\n","loss_function = nn.CrossEntropyLoss()\n","# 最適化手法と学習率の定義\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLKduK1T8vk0"},"outputs":[],"source":["# 学習を通しての損失を記録するためのリスト（学習曲線のプロット用）\n","train_losses = []\n","valid_losses = []\n","\n","# 学習にかかった時間の計測開始\n","start_time = time.time()\n","\n","print(\"\\n【学習開始】\\n\")\n","print(\"train_loss: 学習データにおける損失\")\n","print(\"valid_loss: 検証データにおける損失\\n\")\n","\n","# エポックごとの訓練損失と検証損失を出力\n","print(\"epoch\\ttrain_loss\\tvalid_loss\")\n","\n","for epoch in range(MAX_EPOCH):\n","\tmodel.train()        # モデルを訓練モードに設定\n","\ttrain_loss_list = [] # 訓練損失を保存するリスト\n","\n","\t# 訓練データでモデルを学習\n","\tfor x, label in train_loader:\n","\t\toptimizer.zero_grad()               # 勾配をリセット\n","\t\toutput = model(x)                   # モデルの出力を計算\n","\t\tloss = loss_function(output, label) # 損失を計算\n","\t\tloss.backward()                     # 勾配を計算\n","\t\toptimizer.step()                    # 勾配に基づいてパラメータを更新\n","\t\ttrain_loss_list.append(loss.item()) # バッチごとの損失を記録\n","\n","\ttrain_loss_mean = np.mean(train_loss_list) # エポックごとの平均訓練損失\n","\ttrain_losses.append(train_loss_mean)       # 訓練損失をリストに追加\n","\n","\tmodel.eval()         # モデルを評価モードに設定\n","\tvalid_loss_list = [] # 検証損失を保存するリスト\n","\n","\t# 検証データで損失を計算\n","\tfor x, label in valid_loader:\n","\t\toutput = model(x)                      # モデルの出力を計算\n","\t\tloss = loss_function(output, label)    # 損失を計算\n","\t\tvalid_loss_list.append(loss.item())    # バッチごとの損失を記録\n","\n","\tvalid_loss_mean = np.mean(valid_loss_list) # エポックごとの平均検証損失\n","\tvalid_losses.append(valid_loss_mean)       # 検証損失をリストに追加\n","\n","\tprint(\"{}\\t{:.8}\\t{:.8}\".format(epoch, train_loss_mean, valid_loss_mean))\n","\n","# 学習にかかった時間の計測終了\n","end_time = time.time()\n","print(\"\\n学習にかかった時間 : {} [sec]\".format(end_time - start_time))\n","\n","print(\"\\n【学習終了】\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"os24cyIT8vk0"},"outputs":[],"source":["# 学習曲線のプロット\n","plt.plot(range(MAX_EPOCH), train_losses, label='Training Loss')\n","plt.plot(range(MAX_EPOCH), valid_losses, label='Validation Loss', color=\"green\")\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Learning Curve')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjDa-rzt8vk1"},"outputs":[],"source":["# テストデータを使ってモデルを評価\n","model.eval() # モデルを評価モードに設定\n","test_loss = 0\n","test_correct = 0\n","test_total = 0\n","\n","# テストデータでの損失と正解率を計算\n","for x, label in test_loader:\n","\toutput = model(x)                            # モデルの出力を計算\n","\tloss = loss_function(output, label)          # 損失を計算\n","\t_, pred = torch.max(output.data, dim=1)      # 出力の最大値を持つクラスを予測\n","\ttest_correct += (pred == label).sum().item() # 正解の数をカウント\n","\ttest_total += label.size()[0]                # テストデータの総数をカウント\n","\n","# テストデータにおける正解率を計算して表示\n","test_accuracy = test_correct / test_total\n","print(\"テストデータにおける正解率 : {:.4f}\".format(test_accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"728S5dJb8vk1"},"outputs":[],"source":["# モデルの保存\n","model_dir = \"/content/drive/MyDrive/jts2024_2/model/\"\n","os.makedirs(model_dir, exist_ok=True)\n","save_path = model_dir + \"cnn.pt\"\n","torch.save(model.state_dict(), save_path)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
